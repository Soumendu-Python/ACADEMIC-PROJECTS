# SIGN LANGUAGE GESTURE RECOGNITION
In day-to-day life, computers are becoming a norm. But there are people who are not educated enough to use them. For them using computers even for the basic of requirements is a mountainous task. Also there are specially challenged people who are only know to interact with sign language from their childhood and cannot understand alphabets on the keyboard.

This project is a stepping stone to overcome the problems faced by some unfortunate citizens so they can interact with computers at their workplace or at school, bus stop, railway station etc. and hence can use as easily as we do.

The goal of this project is to recognize the signs and symbols shown by people so the application or the device can understand as what is conveyed and hence give the necessary services required.
This project recognizes 7 kinds of signs that are most commonly used in daily basis. The user shows up his/her hand depicting a symbol and the application in which the following project would be deployed will recognize the word and will process accordingly.
A graphical user interface authorizing the initialization of the application is to be developed for necessary security purposes.

Almost 12000 train images and 8000 validation images were collected and categorized so as to train the model efficiently adapting to different ways of showing up hands using Video Capture in OpenCV library.
A model was built and the images were fed into the model and trained.
At the end, when the hand is shown depicting a particular sign or symbol in front of the webcam, the system will predict as to what the user is trying to convey in real time.

The dataset is large hence it can be found in the given link
https://drive.google.com/file/d/1luAOylVGpEwACVU_yTHWIDL7-uTq4B8x/view?usp=sharing
